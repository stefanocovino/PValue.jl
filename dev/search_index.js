var documenterSearchIndex = {"docs":
[{"location":"#PValue.jl","page":"PValue.jl","title":"PValue.jl","text":"Documentation for PValue.jl\n\nA set of sparse julia functions for computing p-values in a \"frequentist\" or \"Bayesian\" scenario.\n\n","category":"section"},{"location":"#Index","page":"PValue.jl","title":"Index","text":"","category":"section"},{"location":"#PValue.ACF_EK-Tuple{Vector{Float64}, Vector{Float64}, Vector{Float64}}","page":"PValue.jl","title":"PValue.ACF_EK","text":"ACF_EK(t::Vector{Float64},y::Vector{Float64},dy::Vector{Float64}; bins::Int=20)\n\nCompute the auto-correlation function for data irregularly sampled, following the algorithm by Edelson & Krolik (1988). This a porting of the python astroML version.\n\nArguments\n\nt is the vector of observing times.\ny is the vector of fluxes.\ney is the vector of the uncertainties of the fluxes.\n\nReturns a tuple of three value: the ACF, the ACF uncertainties, and the bin limits.\n\nExample\n\nt = [1.1,2.3,3.2,4.5]\ny = [1.,2.,0.5,0.3]\ney = 0.1 .* y\n\nACF_EK(t,y,ey,bins=2)\n([0.6817802730844681, 0.2530024508265458], [0.4472135954999579, 0.5773502691896257], -3.4:3.40000000005:3.4000000001)\n\n\n\n\n\n\n","category":"method"},{"location":"#PValue.BIC-Tuple{AbstractFloat, Integer, Integer}","page":"PValue.jl","title":"PValue.BIC","text":"BIC(lp::AbstractFloat,ndata::Integer,nvar::Integer)\n\nCompute the Bayes Information Criterion.\n\nArguments\n\nlp logarithm of the likelihood.\nndata number of datapoints.\nnvar number of model parameters.\n\nExamples\n\n\nBIC(56.,100,3)\n\n# output\n\n-98.18448944203573\n\n\n\n\n\n","category":"method"},{"location":"#PValue.FourierPeriodogram-Tuple{Any, Any}","page":"PValue.jl","title":"PValue.FourierPeriodogram","text":"FourierPeriodogram(signal,fs;zerofreq=true)\n\nCompute the discrete Fourier periodogram for the inpout signal.\n\nArguments\n\nsignal array of input data.\nfs sampling in frequency of the input data (1/dt).\n'zerofreq' is true (false) to (not) include the zero frequency in the output.\n\nOutputs are two arrays: the frequencies and the powers.\n\nExamples\n\n\nFourierPeriodogram([1.,2.,3.,4.],1.)\n\n# output\n\n([0.0, 0.25], [100.0, 8.000000000000002])\n\n\n\n\n\n","category":"method"},{"location":"#PValue.Frequentist_p_value-Tuple{Any, Any, Any}","page":"PValue.jl","title":"PValue.Frequentist_p_value","text":"Frequentist_p_value(ssrv,ndata,nvar)\nFrequentist_p_value(ssrv,ndof)\n\nCompute the 'classic' frequentist p-value.\n\nArguments\n\nssrv SSR, the sum of squared residuals.\nndata number of datapoints.\nnvar number of fit parameters.\nndof number of degrees of freedom\n\n(i.e. ndata-nvar).\n\nExamples\n\n\nFrequentist_p_value(85.3,100,10)\n\n# output\n\n0.620453567577112\n\nFrequentist_p_value(85.3,90)\n\n# output\n\n0.620453567577112\n\n\n\n\n\n","category":"method"},{"location":"#PValue.Gelman_Bayesian_p_value-NTuple{4, Any}","page":"PValue.jl","title":"PValue.Gelman_Bayesian_p_value","text":"Gelman_Bayesian_p_value(modvecs,simvecs,obsvec,errobsvec)\n\nCompute a 'Bayesian p-value' following the recipe by A. Gelman et al., 2013.\n\nArguments\n\nobsvec datapoints.\nerrobsvec datapoint uncertainties.\nmodvecs model vector.\nsimvecs simulated vector.\n\nExplanation\n\nobsvec and errobsvec are length-'m' vectors of datapoints and relative uncertainties. modvecs is a vector computed by the posterior distribution of parameters (n chains), e.g. by a MCMC, where each component is a vector of m values computed using the fit function and each set of parmeters from the posterior distribution. Finally, simvecs is like modevecs with the addition of the predicted noise, i.e. these are simulated datapoints.\n\nThe routinely essentially compares the SSR (or, in principle, any test statistics) of each model based on the derived posterior distribution of parameters vs the data and to SSR computed by simulated data and again the posterior.\n\nExamples\n\nA full example of application of the GelmanBayesianp_value as well as the LucyBayesianp_value and the Frequentistpvalue is reported in this Jupyter notebook.\n\n\n\n\n\n","category":"method"},{"location":"#PValue.GetACF-Tuple{Any, Any}","page":"PValue.jl","title":"PValue.GetACF","text":"GetACF(data::Vector{Float64},lags::Integer;sigma=1.96,bartlett=false)\n\nCompute the [AutoCorrelation Function[(https://en.wikipedia.org/wiki/Autocorrelation) for the given lags. It returns a dictionary with the ACF and the minimum and maximum uncertainties against a white noise hypothesis.\n\nArguments\n\ndata is the vector of input data.\nlags last lag to be computed.\nsigma number of sigmas for the uncertainties.\nbartlettif a flag driving the error computation. If true Bartlett formula is applied.\n\nExamples\n\n\nGetACF([1.2,2.5,3.5,4.3],2)[\"ACF\"]\n\n# output\n\n3-element Vector{Float64}:\n  1.0\n  0.23928737773637632\n -0.2945971122496507\n\n\n\n\n\n","category":"method"},{"location":"#PValue.GetCrossCorr-Tuple{Vector{Float64}, Vector{Float64}, Integer}","page":"PValue.jl","title":"PValue.GetCrossCorr","text":"GetCrossCorr(x::Vector{Float64},y::Vector{Float64},lags::Integer)\n\nCompute the [crosscorrelation [(https://en.wikipedia.org/wiki/Cross-correlation) between the x and y datasets for the given lags. It returns the cross-correlation values.\n\nArguments\n\nx is the first input vector.\ny is the second input vector.\nlags last lag to be computed.\n\nExamples\n\n\nGetCrossCorr([1.2,2.5,3.5,4.3],[1.5,2.9,3.0,4.1],2)\n\n# output\n\n5-element Vector{Float64}:\n -0.1926156048478174\n  0.1658715565267623\n  0.9627857395579823\n  0.15827215481804718\n -0.15637230439086838\n\n\n\n\n\n","category":"method"},{"location":"#PValue.GetPACF-Tuple{Vector{Float64}, Integer}","page":"PValue.jl","title":"PValue.GetPACF","text":"GetPACF(data::Vector{Float64},lags::Integer;sigma=1.96)\n\nCompute the [Partial AutoCorrelation Function[(https://en.wikipedia.org/wiki/Partialautocorrelationfunction) for the given lags. It returns a dictionary with the PACF and the minimum and maximum uncertainties.\n\nArguments\n\ndata is the vector of input data.\nlags last lag to be computed.\nsigma number of sigmas for the uncertainties.\n\nExamples\n\n\nGetPACF([1.2,2.5,3.5,4.3],1)[\"PACF\"]\n\n# output\n\n2-element Vector{Float64}:\n 1.0\n 0.7819548872180438\n\n\n\n\n\n","category":"method"},{"location":"#PValue.Lucy_Bayesian_p_value-NTuple{4, Any}","page":"PValue.jl","title":"PValue.Lucy_Bayesian_p_value","text":"Lucy_Bayesian_p_value(modvecs,obsvec,errobsvec,nvars)\n\nCompute a 'Bayesian p-value' following the recipe by L.B. Lucy, 2016, A&A 588, 19.\n\nArguments\n\nobsvec datapoints.\nerrobsvec datapoint uncertainties.\nnvars number of parameters.\n\nExplanation\n\nobsvec and errobsvec are length-m vectors of datapoints and relative uncertainties. modvecs is a vector computed by the posterior distribution of parameters (n chains), e.g. by a MCMC, where each component is a vector of m values computed using the fit function and each set of parmeters from the posterior distribution. Finally, nvars is the number of parameters.\n\nThis algorithm relies on the Chi2 distribution as in the 'frequentist' case. Howver the SSR is not based only on a punt estimate but it is computed by the whole posterior distribution of parameters.\n\nExamples\n\n\nx = [1,2,3,4,5]\ny = [1.01,1.95,3.05,3.97,5.1]\ney = [0.05,0.1,0.11,0.17,0.2]\n\nf(x;a=1.,b=0.) = a.*x.+b\n\n# Sample from a fake posterior distribution\nch = DataFrame(a=[0.99,0.95,1.01,1.02,1.03], b=[0.,-0.01,0.01,0.02,-0.01])\n\nres = []\nfor i in 1:nrow(ch)\n    push!(res,f(x;a=ch[i,:a],b=ch[i,:b]))\nend\n\nLucy_Bayesian_p_value(res,y,ey,2)\n\n# output\n\n0.7200318895143041\n\n\n\n\n\n","category":"method"},{"location":"#PValue.RMS-Tuple{Any, Any}","page":"PValue.jl","title":"PValue.RMS","text":"RMS(datavec,modvec)\n\nCompute the Root Mean Square value.\n\nArguments\n\ndatavec datapoints.\nmodvec model values.\n\nExamples\n\n\nRMS([1.1,2.2],[1.15,2.15])\n\n# output\n\n0.050000000000000044\n\n\n\n\n\n","category":"method"},{"location":"#PValue.SSR-Tuple{Any, Any, Any}","page":"PValue.jl","title":"PValue.SSR","text":"SSR(modvec,obsvec,errobsvec)\n\nCompute the Sum of Squared Residuals.\n\nArguments\n\nmodvec model predictions.\nobsvec observed data.\n`errobsvec~ uncertainties.\n\nExamples\n\n\nSSR([1.,2.,3.,4.],[1.1,1.9,3.05,3.8],[0.1,0.05,0.2,0.1])\n\n# output\n\n9.062500000000016\n\n\n\n\n\n","category":"method"},{"location":"#PValue.SigmaClip","page":"PValue.jl","title":"PValue.SigmaClip","text":"SigmaClip(x, ex=ones(size(x)); sigmacutlevel=2)\n\nSigma-clipping filtering of an input array,\n\nArguments\n\nx input array.\nex uncertainties.\nsigmacutlevel sigma-clipping level.\n\nIt performs a one-iteration sigma clipping and reports a mask to select the surviving elements in the input arrays or other related arrays.\n\nExamples\n\n\nx = [4.,6.,8.,1.,3.,5.,20.]\nmask = SigmaClip(x)\nx[mask]\n\n# output\n\n6-element Vector{Float64}:\n 4.0\n 6.0\n 8.0\n 1.0\n 3.0\n 5.0\n\n\n\n\n\n","category":"function"},{"location":"#PValue.WeightedArithmeticMean-Tuple{Any, Any}","page":"PValue.jl","title":"PValue.WeightedArithmeticMean","text":"WeightedArithmeticMean(x,ex)\n\nCompute the Weighted Arithmetic Mean.\n\nArguments\n\nx input vector\nex uncertainties.\n\nExamples\n\n\nx = [1.2,2.2,4.5,3,3.6]\nex = [0.2,0.2,0.5,0.1,0.6]\n\nWeightedArithmeticMean(x,ex)\n\n# output\n\n(2.634301913536499, 0.07986523020975032)\n\n\n\n\n\n","category":"method"},{"location":"#PValue.Z2N-Tuple{Any, Any}","page":"PValue.jl","title":"PValue.Z2N","text":"Z2N(freqs, time)\n\nCompute the Rayleigh power spectrum of a time series in a given range of frequencies.\n\nArguments\n\nfreqs is an array with frequencies in units of 1/[time].\ntime is an array with the time series where to find a period.\nharm is the number of harmonics to be used in the analysis.\n\nExamples\n\n\nZ2N([1.,0.5,0.25], [1.,2.,2.5,3.5,5.])\n\n# output\n\n3-element Vector{Any}:\n 0.4\n 0.4000000000000002\n 0.537258300203048\n\n\n\n\n\n","category":"method"}]
}
